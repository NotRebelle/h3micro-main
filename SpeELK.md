```
üê≥ Sp√©cifications projet System design - ELK üê≥

Int√©gration ELK dans votre architecture micro service existantes 

Int√©grer Elasticsearch avec votre backend en ajoutant/rempla√ßant votre base actuelle dans votre docker-compose file (vous pouvez vous appuyer sur le cours en ligne et les example de compose files)
Int√©grer Logstash dans votre projet pour effectuer le traitement et l'agr√©gation des logs (vous pouvez g√©n√©rer des logs si votre application n‚Äôen produit pas assez/pas du tout)
D√©velopper minimum une pipeline Logstash qui collecte, traite et transf√®re les logs vers Elasticsearch et l'inclure dans le fichier docker-compose.yml
Ajouter le service Metricbeat pour collecter et transf√©rer diverses m√©triques syst√®me et de service vers Elasticsearch et inclure Metricbeat dans le docker-compose.yml
 
Streaming de donn√©es avec Logstash

Mettre en place un m√©canisme ou un script de streaming de donn√©es qui g√©n√®re et envoie des donn√©es √† Logstash (vous pouvez vous appuyer sur les examples du cours)
Assurer que vos donn√©es real time soient correctement format√©es et envoy√©es √† Logstash pour traitement (minimum une custom pipeline avec des donn√©es diff√©rentes du cours).
 

Tests et validation de pipelines

Cr√©er des scripts de test pour valider le bon fonctionnement de Elastic, Logstash et Metricbeat, ainsi que du script de streaming de donn√©es.
S'assurer que l'int√©gration de ces outils n'introduise aucun probl√®me dans la configuration existante. 
Vous avez a minima des fichiers (bash ou autre) de tests qui : 
test la sant√©e de vos conteneurs
test le bon fonctionnement de votre application (front / back)
test du bon fonctionnement de votre stack ELK 
test automatis√©s dans votre docker-compose-file (minimum 3) 
Fonctionnalit√©s Applicative 

Impl√©menter des fonctionnalit√©s de recherche dans le frontend qui exploitent Elasticsearch.
Impl√©menter la fonctionnalit√© d‚Äôauto-completion de Elasticsearch dans votre front. 
Implementer un syst√®me d‚Äôauthentification (JWT, OAuth, SSO‚Ä¶) 
ex de service auth : https://www.youtube.com/watch?v=hmkF77F9TLw&t=2054s / https://github.com/kantancoding/microservices-python 
Surveillance continue du flux stream 

Int√©grer Elasticsearch avec Kibana pour la visualisation de donn√©es et la surveillance en temps r√©el.
Fournir un screen shot dans votre readme a la racine de votre GitHub du tableau de bord Kibana dans le cadre de votre solution de surveillance.
Implementer un dashboard kibana avec vos donn√©es en real time  
Implementer une action d‚Äôintegration continue avec elastic curator tool (cf comme dans le chapitre ELK/monitoring de la doc fournie en cours)
 

Documentation de l'Architecture

Mettre √† jour le diagramme d'architecture de votre projet pour inclure Elasticsearch, montrant son r√¥le et son interaction avec d'autres composants/services que vous d√©taillerez en description.
Votre README.md √† la racine de votre GitHub contient les explications n√©cessaires pour build et run votre projet ainsi qu‚Äôune demo online sans erreur et/ou screen shot. 
 

Suivie continue üöÄ

Vous devez envoyer un push GitHub par demi journ√©e (au minimum)
Si vous rencontrer un probl√®me bloquant votre avancement ouvrir une issue GitHub (avec screen shot) et contacter le professeur en message priv√©e en envoyant le lien ```
